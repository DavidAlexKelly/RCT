#!/bin/bash
# ui/launch.sh - Launch the Regulatory Compliance Analyzer UI

echo "üöÄ Starting Regulatory Compliance Analyzer UI..."
echo "üìç The UI will be available at: http://localhost:8501"
echo ""

# Get the directory where this script is located
UI_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )"
PROJECT_ROOT="$(dirname "$UI_DIR")"

echo "üìÇ UI Directory: $UI_DIR"
echo "üìÇ Project Root: $PROJECT_ROOT"
echo ""

# Check if we're in the right directory
if [ ! -f "$UI_DIR/app.py" ]; then
    echo "‚ùå Error: app.py not found in $UI_DIR"
    echo "Please run this script from the ui/ directory"
    exit 1
fi

# Check if main project files exist
if [ ! -f "$PROJECT_ROOT/compliance_analyzer.py" ]; then
    echo "‚ùå Error: Main compliance analyzer not found"
    echo "Please ensure you're running from the correct project structure"
    exit 1
fi

# Install UI requirements if needed
if [ ! -f "$UI_DIR/.requirements_installed" ]; then
    echo "üì¶ Installing UI requirements..."
    
    if [ -f "$UI_DIR/requirements.txt" ]; then
        pip install -r "$UI_DIR/requirements.txt"
        if [ $? -eq 0 ]; then
            touch "$UI_DIR/.requirements_installed"
            echo "‚úÖ UI requirements installed successfully"
        else
            echo "‚ùå Failed to install UI requirements"
            exit 1
        fi
    else
        echo "‚ö†Ô∏è  No requirements.txt found, skipping installation"
    fi
    echo ""
fi

# Check if Ollama is running
echo "üîç Checking Ollama status..."
if command -v ollama &> /dev/null; then
    if pgrep -x "ollama" > /dev/null; then
        echo "‚úÖ Ollama is running"
    else
        echo "‚ö†Ô∏è  Ollama is not running. Starting Ollama..."
        ollama serve &
        sleep 3
        echo "‚úÖ Ollama started"
    fi
else
    echo "‚ùå Ollama not found. Please install Ollama first:"
    echo "   Visit: https://ollama.ai"
    exit 1
fi

# Check for required models
echo "ü§ñ Checking available models..."
MODELS=$(ollama list 2>/dev/null | grep -E "llama3:" | wc -l)
if [ "$MODELS" -eq 0 ]; then
    echo "‚ö†Ô∏è  No Llama3 models found. You may need to install a model:"
    echo "   ollama pull llama3:8b"
    echo "   (continuing anyway...)"
else
    echo "‚úÖ Found $MODELS Llama3 model(s)"
fi

echo ""
echo "üåü All checks passed! Launching Streamlit app..."
echo ""

# Change to the UI directory and launch Streamlit
cd "$UI_DIR"

# Launch Streamlit with the app
streamlit run app.py \
    --server.port 8501 \
    --server.address localhost \
    --browser.serverAddress localhost \
    --browser.serverPort 8501 \
    --server.headless false \
    --server.runOnSave true \
    --theme.base "light" \
    --theme.primaryColor "#667eea" \
    --theme.backgroundColor "#ffffff" \
    --theme.secondaryBackgroundColor "#f0f2f6"